<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Cache Memory</title><style>
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark-href {
	font-size: 0.75em;
	opacity: 0.5;
}

.sans { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, KaiTi, STKaiTi, 'ÂçéÊñáÊ•∑‰Ωì', KaiTi_GB2312, 'Ê•∑‰Ωì_GB2312', serif; }
.mono { font-family: Nitti, 'Microsoft YaHei', 'ÂæÆËΩØÈõÖÈªë', monospace; }
.pdf .sans { font-family: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .code { font-family: Source Code Pro, 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, KaiTi, STKaiTi, 'ÂçéÊñáÊ•∑‰Ωì', KaiTi_GB2312, 'Ê•∑‰Ωì_GB2312', serif, 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .mono { font-family: PT Mono, Nitti, 'Microsoft YaHei', 'ÂæÆËΩØÈõÖÈªë', monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.highlight-default {
}
.highlight-gray {
	color: rgb(155,154,151);
}
.highlight-brown {
	color: rgb(100,71,58);
}
.highlight-orange {
	color: rgb(217,115,13);
}
.highlight-yellow {
	color: rgb(223,171,1);
}
.highlight-teal {
	color: rgb(15,123,108);
}
.highlight-blue {
	color: rgb(11,110,153);
}
.highlight-purple {
	color: rgb(105,64,165);
}
.highlight-pink {
	color: rgb(173,26,114);
}
.highlight-red {
	color: rgb(224,62,62);
}
.highlight-gray_background {
	background: rgb(235,236,237);
}
.highlight-brown_background {
	background: rgb(233,229,227);
}
.highlight-orange_background {
	background: rgb(250,235,221);
}
.highlight-yellow_background {
	background: rgb(251,243,219);
}
.highlight-teal_background {
	background: rgb(221,237,234);
}
.highlight-blue_background {
	background: rgb(221,235,241);
}
.highlight-purple_background {
	background: rgb(234,228,242);
}
.highlight-pink_background {
	background: rgb(244,223,235);
}
.highlight-red_background {
	background: rgb(251,228,228);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(55, 53, 47, 0.6);
	fill: rgba(55, 53, 47, 0.6);
}
.block-color-brown {
	color: rgb(100,71,58);
	fill: rgb(100,71,58);
}
.block-color-orange {
	color: rgb(217,115,13);
	fill: rgb(217,115,13);
}
.block-color-yellow {
	color: rgb(223,171,1);
	fill: rgb(223,171,1);
}
.block-color-teal {
	color: rgb(15,123,108);
	fill: rgb(15,123,108);
}
.block-color-blue {
	color: rgb(11,110,153);
	fill: rgb(11,110,153);
}
.block-color-purple {
	color: rgb(105,64,165);
	fill: rgb(105,64,165);
}
.block-color-pink {
	color: rgb(173,26,114);
	fill: rgb(173,26,114);
}
.block-color-red {
	color: rgb(224,62,62);
	fill: rgb(224,62,62);
}
.block-color-gray_background {
	background: rgb(235,236,237);
}
.block-color-brown_background {
	background: rgb(233,229,227);
}
.block-color-orange_background {
	background: rgb(250,235,221);
}
.block-color-yellow_background {
	background: rgb(251,243,219);
}
.block-color-teal_background {
	background: rgb(221,237,234);
}
.block-color-blue_background {
	background: rgb(221,235,241);
}
.block-color-purple_background {
	background: rgb(234,228,242);
}
.block-color-pink_background {
	background: rgb(244,223,235);
}
.block-color-red_background {
	background: rgb(251,228,228);
}

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="718834f4-e1ce-4354-9eec-df397833cac1" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">üöÖ</span></div><h1 class="page-title">Cache Memory</h1><table class="properties"><tbody></tbody></table></header><div class="page-body"><h1 id="00a1806f-93eb-4198-9a2f-0c7a20f2f5b1" class="">Overview</h1><p id="3dfc690b-fb8e-4095-bf7e-f9033c4ba768" class="">Access to the main memory (also known as system memory) by the CPU, is a <strong>slow</strong> operation.</p><p id="14f55bcf-e595-4a4e-9bd4-87910c35dca1" class="">Therefore, a set of memory caches are used by the CPU.</p><p id="21f25d44-8db6-472b-a8f2-bb3e3cc74838" class=""><strong>Caches</strong> are smaller banks of memory.</p><h1 id="d7b8f918-00f9-4363-91de-f385f1f72339" class="">Cache Levels</h1><p id="6cb01f71-9d38-4bdf-80ba-d769bd33bc13" class="">There is a tradeoff between cache latency and hit rate. Larger caches have better hit rates but longer latency.</p><p id="b1eb6fec-a498-4473-9ee1-dc299e76468e" class="">For this reason, moderns CPU have two or three levels of cache.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="25892b5c-1c0b-414c-bd58-b351053f0733"><div style="font-size:1.5em"><span class="icon">‚ÑπÔ∏è</span></div><div style="width:100%">The levels of cache in the cache hierarchy are referred to as Level 1 (L1), Level 2 (L2), and Level 3 (L3).</div></figure><p id="33440d61-67e9-44ad-bec9-15fe3e606a89" class="">The L1 cache is divided into two uses:</p><ul id="87890b96-2820-400c-b59f-3a9b6c99fa00" class="bulleted-list"><li>The¬†<em>instruction cache</em> holds copies of the instructions to execute.</li></ul><ul id="7641e803-bd22-4c69-81ef-1b4145707fd5" class="bulleted-list"><li>The¬†<em>data cache</em> holds copies of memory that are read and written by the instructions.</li></ul><p id="e967cc96-8638-4e8e-9cb2-4bcf98c20a52" class="">The L2 and L3 caches are typically <em>unified caches</em> containing both instructions and data.</p><p id="2583de16-7e33-4c21-8813-74fbd90f682a" class="">Higher levels of cache contain more memory that the previous level of cache but are also slower.</p><p id="d312e426-a3fd-4c07-8761-c1e6be1f5819" class="">Different architectures have different levels of cache. Generally, there are three levels of cache and the level 3 cache is shared between the cores.</p><p id="3b467307-2958-4b10-9a51-01000cab4c39" class="">The L1 cache is generally located on the CPU itself and is fastest to access.</p><p id="24c7cb86-a935-4774-8818-2c8531080978" class="">Higher levels of cache are generally located on external chips but are still faster to access than main memory.</p><h2 id="f0e8a8cf-6f92-4323-b2cd-8eaf9de4a4e6" class="">Memory Access</h2><p id="a9a42d6e-5363-44b5-b59b-30b5ce289d5c" class="">When the processor tries to access a memory address:</p><ul id="0bc8198c-9baa-4258-98de-b56fc8f61ee9" class="bulleted-list"><li>It checks the fastest L1 cache first.</li></ul><ul id="95fc1ce3-b963-407e-8991-3bd8ae7cc36c" class="bulleted-list"><li>If there is a cache hit, the processor proceeds at high speed without checking higher levels of cache, and more importantly without accessing the main memory.</li></ul><ul id="2671cfaa-aa60-4b1a-9203-5ec39c67b26e" class="bulleted-list"><li>If there is a cache miss, the next fastest cache is checked.</li></ul><ul id="eab63b4b-05c5-4138-b564-2f2c58fa4c15" class="bulleted-list"><li>The processor checks higher and slower levels of cache until there is a cache hit.</li></ul><ul id="63b131e5-b957-4fde-9c96-06360d5aad28" class="bulleted-list"><li>If the data is does not exist in any level of cache, the data is copied from main memory to the cache.</li></ul><h2 id="d1973c06-d2e5-4722-b9e1-62f67d78c5fd" class="">Architectures</h2><p id="83055579-bbf6-4383-bf6b-466fdf52a306" class="">On Intel i7 processors, the L1 cache is 32 KB and dedicated to each core.
The L2 cache is 256 KB and shared by each cluster.
The L3 cache is 6 MB to 8 MB and shared by all the cores.</p><p id="d582912f-ecda-4134-a4df-a1b3e714c027" class="">The Xbox One and the PS4 have dual quad-core processors.
There are only two levels of cache, but with an additional bridge between the split L2 caches. The size of the L2 is also increased to 4 MB.</p><h1 id="61754fa3-e7ad-45e6-8274-f1af281a7fb3" class="">Cache Lines</h1><p id="6bd4f163-86e3-4e4d-82db-dff2954c995d" class="">Each cache is organized into fixed-size units called <em>cache lines</em>.</p><p id="aece000e-cee6-4293-8f1d-68a9f51e7921" class="">They size is typically a power of two value.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="b743517b-39a7-46d0-b6bb-d63b3ae94666"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%">Moderns CPUs generally have 64-bytes cache lines.</div></figure><p id="e35acda7-896b-442b-98dd-53694872dfcb" class="">When a program references a memory address, the CPU loads a cache line by copying from system memory beginning at the next-lowest address that is aligned with the size of a cache line.</p><p id="28d212fd-938c-4793-9e41-e82e12bac184" class="">Therefore, properly aligning data allows a better use of the cache line.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="af89e536-15e7-43ac-9225-34932d4f4f29"><div style="font-size:1.5em"><span class="icon">‚ö†Ô∏è</span></div><div style="width:100%">Even when a single byte not in the cache, the full cache line is read from main memory.</div></figure><p id="3f23ff79-a621-495e-a645-aad5b755d20e" class="">Predictable access patterns are very prefetch-friendly.</p><p id="9fceee06-5450-4988-88cb-8bab5e0ff9ae" class="">For example, linear array traversals are very cache-friendly (see locality).</p><h1 id="083ee13e-732d-4772-8a7a-9f7a1804db21" class="">Cache Misses</h1><p id="62f48f01-da34-477d-8e25-d5981a1d7583" class="">Cache hits and cache misses occur when a memory address is read or written by the CPU.</p><p id="6f16ec25-9d35-44ea-84ab-ca9ec829ea8d" class="">When the CPU tries to access a memory address:</p><ul id="c5ce3047-265b-4686-b99c-c1aa5c21d658" class="bulleted-list"><li>If the memory address is in the cache, a <em>cache hit</em> occurs.</li></ul><ul id="ff0a80e0-8364-4a34-bca5-6070f6f5ca92" class="bulleted-list"><li>If the memory address is not in the cache, a <em>cache miss</em> occurs.</li></ul><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="acadcc44-c767-4f9f-b27a-194148af11b2"><div style="font-size:1.5em"><span class="icon">‚ö†Ô∏è</span></div><div style="width:100%">An excessive number of cache misses can significantly impact performance.</div></figure><p id="92d71dff-331b-44d5-acf4-f2e2a7b662c0" class="">Cache misses can be avoided by strategic use of memory by promoting <em>locality of reference</em>.</p><p id="064466c6-3576-432a-a513-9b9ba6cd66db" class="">The benefit of locality of reference is to increase the likelihood that data is already in the cache when instructions need access to it. The data should ideally fit in a cache line.</p><h2 id="9658e48d-a390-4537-b3c4-8f83220c8fe5" class="">Spatial locality</h2><p id="97ba6774-803c-4587-a833-f48777f044db" class="">Spatial locality is the use of data structures within close memory locations.</p><p id="a78c906d-1e7c-4da2-a2e5-7ef94cb86d34" class="">To benefit from spatial locality, keep data structures close together in memory.</p><p id="de77dbfb-f649-42f4-ba75-b9688ebe29a6" class="">In other words, if a block of memory is accessed by the CPU, there is a good chance that adjacent memory blocks will also be touched by the CPU.</p><h2 id="a0808886-17ad-4b9d-b101-44377545a11f" class="">Temporal locality</h2><p id="6eb6891d-45e8-4d17-9aef-f1511128ad3b" class="">Temporal locality is the reuse of data structures within a small time duration.</p><p id="71ac54d1-25f0-4dd0-a33e-e0dc9ff7a887" class="">To benefit from temporal locality, the code should keep access to data structures as close in time as possible.</p><p id="04b5962e-c1a5-4a60-bbd8-e672ff550547" class="">In other words, if a block of memory is accessed by the CPU, there is a good chance that it will be accessed again in a short amount of time.</p><h1 id="27db867e-77e0-4b09-9930-b149083cf9b5" class="">Cache Trashing</h1><p id="c4c93f39-3c39-48b3-829f-6c22bc6d4794" class="">Poor locality results in cache thrashing and cache pollution.</p><p id="4ec1a611-5450-4c26-a88a-c943b7263aee" class="">Cache trashing occurs when multiple memory locations compete for the same cache lines and result in excessive cache misses.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="d03d674b-51d8-43d3-93ad-1e02e8a17ced"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%">It can occur when a cache level is shared by multiple cores, and a multithreading algorithm do not efficiently share data.</div></figure><p id="37d79d38-30f6-4aca-a743-49ffbd24b46c" class="">Cache pollution occurs when unnecessary data is loaded into the CPU cache causing other useful data to be evicted from the cache.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="53c3b616-3614-4bbe-876a-a76c90970800"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%">It can occur when an algorithm works on a data structure that is interleaved with data members that are not used in the algorithm.</div></figure><h1 id="8ba6c91c-16de-46ba-9ef5-900c6b90b48d" class="">Loads and Stores</h1><p id="e6e3b223-4d27-42fb-91de-081b6f5d2650" class="">A <em>c</em><em><strong>ache load</strong></em> occurs when the CPU copies data from the main memory to the caches.</p><p id="78eb232c-9b8a-44c1-851a-2cb522aa9260" class="">A <em>c</em><em><strong>ache flush</strong></em> (or <em>store</em>) occurs when the CPU copies data back from the caches to the main memory.</p><h1 id="06948c94-bef8-4d68-848a-751d944596f6" class="">Load-Hit-Stores</h1><p id="8c5bd38e-8189-4059-87bc-2e1e32889c88" class="">Data that was just written is not immediately available for reading.</p><p id="cb0bb977-9b5d-4590-9443-ea3f990859fb" class="">A load-hit-store occurs when a thread stores data to a memory location and shortly afterward reloads from that same location.</p><p id="66a31352-4e1c-4ad8-840d-5f779fa9f0ba" class="">There are several possible causes of a load-hit-store.</p><ul id="2b8392a8-cc86-44cf-8a5a-6d0396b525cc" class="bulleted-list"><li>Transferring data between register sets</li></ul><ul id="3a04cdc1-3f5e-4f28-95ee-0c2b458a8bff" class="bulleted-list"><li>Updating data in arrays</li></ul><ul id="684da740-b0b4-4940-a4a4-326b4423c67d" class="bulleted-list"><li>Passing structures by value</li></ul><h2 id="13ca5448-ef4d-42f1-869b-497ec5a74b7f" class="">Transferring Data between Register Sets</h2><p id="5130b772-e079-4cd0-a627-f85517b355b7" class="">Data is transferred between register sets when performing type conversions (for example, float to integer and integer to float conversions).</p><p id="bd6f69d2-6bfe-4c20-b66e-6a2cda8b0cae" class="">A data transfer between register sets can only be done by going through memory.</p><h2 id="6bc0b8db-0f5f-41b5-afc4-ff0cdbd13a5a" class="">Updating Data in Arrays</h2><p id="4a875efc-abcc-42b9-9f3f-af3dc9cf899f" class="">Frequent read-modify-write sequences to the same element of an array can cause a load-hit-store.</p><p id="2cf8770f-c034-450c-8b57-c603e5492cf7" class="">When writing data through a pointer that is not marked as¬†<strong>restrict</strong>, the compiler assumes that other variables are potentially being overwritten which may force the compiler to flush their values to memory and reload them later.</p><h2 id="b70a46da-25ac-4d88-a10e-dec8857f3f4c" class="">Passing Structures by Value</h2><p id="94bcb805-a29f-4598-b138-b03fbb01f44d" class="">Function calls that pass structures by value may have to pass the structures in memory.</p><p id="8882811e-f29e-44e6-b5b8-9669517a76e2" class="">The calling function writes the structure to the stack, and the called function reads it back, causing a load-hit-store.</p><h1 id="4de49df0-c68a-4b30-bd9d-02375ae33c82" class="">Virtual Memory</h1><p id="9a5f7e33-dda1-422b-a8f0-e5bf5d7951e2" class="">Read and write instructions specify memory addresses in the virtual memory address space.</p><p id="8359103c-1f0b-4759-b6a6-a80cf768a159" class="">Virtual addresses are mapped to physical memory addresses.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="5883d027-0b5f-4699-8606-b69299acf652"><div style="font-size:1.5em"><span class="icon">‚ö†Ô∏è</span></div><div style="width:100%">Contiguous virtual addresses != Contiguous physical memory addresses</div></figure><p id="409de4f5-065e-4386-86cf-babef7c36050" class="">The address translation is performed by the <em>Memory Management Unit</em> (MMU) using a <em>Translation Look-aside Buffer</em> (TLB).</p><p id="5b05d775-c9d2-4d9b-b9b5-ec1bf0bfb112" class="">Virtual memory is used only by CPUs. GPUs and audio hardware need contiguous physical memory.</p><h2 id="4982254b-cf2f-4b37-a761-b706adabff3e" class="">Pages</h2><p id="f5c4b761-d80d-4d13-9a22-d2b262ed6c8f" class="">The CPU divides memory into pages.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="307e34a0-d735-4e30-89c6-c0e7c07594fa"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%">A x86 CPU generally uses 4 KB pages.</div></figure><h2 id="3fc61865-837b-4d7c-a538-b37ef9f0ef6c" class="">Translation Look-aside Buffer</h2><p id="c48593c7-2314-4231-94be-4605fc6a50bd" class="">Before a read or write instruction can be executed, the CPU needs to translate the virtual address to a physical memory address.</p><p id="a84c59a9-d9d5-461e-9d88-3aaf790d56a5" class="">Each CPU core has a <em>Translation Look-aside Buffer</em> (TLB) which is a virtual-to-physical translation cache used for both code and data.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="a4aae7a0-c1e0-4529-ac30-bfebe9d8f624"><div style="font-size:1.5em"><span class="icon">‚ÑπÔ∏è</span></div><div style="width:100%">The lookup is implemented by dividing the virtual address by the relevant page size and sending the result through a hash function to generate a number used to select a set TLB entries.</div></figure><h1 id="3944f4c8-d2ad-46a3-b1fb-a3429284e5c3" class="">Coherency</h1><h2 id="27e4c56d-56f5-410a-a90c-e3b810fa1dfa" class="">Coherent</h2><p id="bc9700e4-3919-442f-b7d6-d944cef4ba9c" class="">Coherent means that the memory access from other clients can snoop CPU caches.</p><p id="f6c19227-3099-4766-980c-5be7af0caad6" class="">Coherent clients must explicitly flush modified data from their caches for any latest-modified copy to become visible to the CPU.</p><h2 id="dea05dfa-40f6-4e51-a1e3-6189523cb15a" class="">Fully-coherent</h2><p id="288364f3-ed15-466b-839e-ab7f9e6604d3" class="">Fully coherent means that the CPU does not need to explicitly flush caches in order for the latest copy of modified data to be available.</p><h1 id="c4e8e67b-a98d-4e85-b638-673f55ead7bf" class="">Memory Types</h1><p id="5d5ee6b7-95b5-4179-ac89-0647ee32450c" class="">There are three memory types: cacheable (default), write-combined, and non-cached.</p><h2 id="b9101c6a-be60-4e4b-bac5-b884991cf723" class="">Cachable</h2><p id="3ec178c0-2630-475d-8987-21bf87efc95b" class="">Loads from cacheable memory involve fetching data in aligned units of 64 bytes known as cache lines.</p><h2 id="52672e32-9e92-49f1-986f-9dd4e47646f6" class="">Write-combined</h2><p id="d40f23bf-a55c-4476-bf5e-21779d630353" class="">Load/stores bypass the data cache, reducing pressure on the cache.</p><p id="107b6d59-c425-426c-b941-48f324e5bc28" class="">Stores are batched into 64-byte write-gather buffers and later directly written to main RAM in bursts.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="377366cc-12f5-4268-8ee6-453ffbb44a95"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%">Write-combined memory should only be used to write data that is not read by the CPU but is later read by the GPU.</div></figure><h1 id="627c8fc7-1303-429e-b479-ae5793816fc6" class="">Branch Prediction</h1><p id="cda66352-69f5-426e-999a-ec076f712540" class="">Speculative out-of-order execution means that each core can speculatively execute instructions before the address of a jump target has been resolved.</p><p id="6ee01c07-a42b-4df2-affb-ad99ce278eea" class="">The branch predictor is responsible for supplying the address at which to start speculative execution.</p><p id="10a2f396-80b1-4165-bf2c-587f1c1ad788" class="">Without speculative execution, the CPU would have to stall, waiting for the resolution of the address at which to continue execution.</p><p id="d901218f-baed-4a3b-8fe8-8454ab2e8fee" class="">If the branch predictor mispredicts the address, all speculative instructions are discarded and never retired.</p><h1 id="a6f7342c-d3d3-40d0-bb05-e424e1323e6d" class="">Policies</h1><p id="47a49317-5814-4bea-ba8b-7c15836059c3" class="">On modern architectures:</p><ul id="ec91b870-0df9-478c-b044-a64b95e78304" class="bulleted-list"><li>L1 is no-allocate and write-through.</li></ul><ul id="d82e9b79-bc47-4f47-8564-0bb16cc52ea4" class="bulleted-list"><li>L2 is write-allocate and write-back.</li></ul><h2 id="1dd9edda-eb94-4aff-8944-2ff4c5b157ac" class="">Write-allocate</h2><p id="4c8b67d0-20bd-49f7-86a6-5b93f98ebd12" class="">Write-allocate means that when writing to an address that is not already in the cache, then a cache line will be allocated for it.</p><h2 id="c40747c1-f846-475e-b85f-9910a4dd34bf" class="">No-allocate</h2><p id="129dde2d-2b1b-4956-87f1-cc544b1b3636" class="">No-allocate means that when writing to an address that is not already in the cache, then the data will not be stored in the cache.</p><p id="a1c3ba01-46fb-4782-83f8-3f15fd590249" class="">It avoids wasting space with data that is never read.</p><h2 id="80dcfa33-e808-4d14-b02f-319dc13e0df8" class="">Write-back</h2><p id="9de2dc8c-b8fc-4ac8-9dfb-8474c1c7fb96" class="">Write-back means that writes to the cache are not written to memory or the next cache until they have to be.</p><h2 id="e49bc25d-57a4-4653-b795-b8b0580e2110" class="">Write-through</h2><p id="a731219f-a81f-4772-85ea-53caa1346f81" class="">Write-through means that modified data is immediately written to memory or the next cache, and never updated in the current cache.</p><p id="a3bb9be1-24a9-4d6b-b7ad-2947b9478136" class="">It ensures that synchronizing data between processors is always fast because there is never any modified data stored in a lower caches that needs to be flushed to a higher cache.</p><h1 id="f9b6e0d8-1c01-413a-92e4-0c8dd71d6235" class="">Best Practices</h1><h2 id="d2b0c26f-da63-4f11-a967-ad849ac671fd" class="">General</h2><p id="c5788b7d-a7e4-47f7-86d9-20834918c963" class="">Code and data structures must be laid out to maximize cache efficiency.</p><p id="ec957409-8fd5-4dc3-a13b-da9eb72cb575" class="">Work with contiguous structures. Dynamic structures cause more cache misses.</p><p id="53e0f70e-9cb8-4fa3-99e3-74428e8a208b" class="">Pack and unpack data in registers with specific SIMD instructions.</p><p id="747c071e-0951-457e-9ba1-313ad52c9529" class="">Hot/cold split data structures to prevent loading unneeded data into the cache.</p><h2 id="88064cd5-181a-4ce1-b5b9-275382ed1d1e" class="">Thread affinity</h2><p id="261fcc7f-a025-4c3f-91d7-918fae45bdf2" class="">On systems with a split L2 cache, two threads on different modules working with the same data set will incur heavy penalties through remote L2 and L1 latencies.</p><h2 id="a2fd51ab-f279-46ec-b787-98c86712982e" class="">Branch Misprediction</h2><p id="32517b00-bbc7-4bba-92d4-d70049cf2749" class="">In very critical code, avoid:</p><ul id="d5223072-9e14-4f93-bc59-d0b8d5952ecb" class="bulleted-list"><li>virtual function calls.</li></ul><ul id="0f8074df-d185-40e8-81e2-4418f4852dde" class="bulleted-list"><li>function pointer dereferences.</li></ul><ul id="258e4f28-a6f8-48e8-be8c-848e0bd27fd8" class="bulleted-list"><li>switch statements based on effectively random data.</li></ul><h2 id="08494290-560e-4e10-8761-b44f1c9539f3" class="">Data Cache</h2><ul id="8b148d0c-ef3c-49fb-bf1e-1a043fd6f410" class="bulleted-list"><li>Perform linear array traversals.</li></ul><ul id="313d97be-25f8-402f-ae06-62d72c83adde" class="bulleted-list"><li>Use as much of a cache line as possible.</li></ul><h2 id="9793c4e4-885a-4788-84da-10b595dd5a6c" class="">Instruction Cache</h2><ul id="08160cca-a370-4f1f-a512-7bbdfc6e5314" class="bulleted-list"><li>Fit working set in cache.</li></ul><ul id="e91fc073-ad58-402f-ae67-50df4572d6d7" class="bulleted-list"><li>Reduce branching.<ul id="214db0bb-5886-43c0-a529-a640c302b07f" class="bulleted-list"><li>modern branch predictors have high accuracy.</li></ul><ul id="d67245b9-4657-458e-8af4-4a8e38a4735d" class="bulleted-list"><li>avoid cost of branch misprediction.</li></ul></li></ul><ul id="5b1e4430-aefe-42f6-b6e3-af21d567062d" class="bulleted-list"><li>Inline cautiously.<ul id="bc1c85ba-72b8-46f2-a8b5-2695eba1a1fd" class="bulleted-list"><li>can increase data cache misses.</li></ul><ul id="d95006c3-07a8-44a8-bf2a-5b4f8554eb5d" class="bulleted-list"><li>can decrease instruction cache misses.</li></ul></li></ul><h1 id="92ec7920-70fc-4c98-884b-b0632ba9ee52" class="">Examples</h1><h2 id="a4769ae6-91fa-4f9a-be39-4e639a566bb7" class="">Matrix Multiplication</h2><p id="e225ea94-0e0b-435b-9244-fc92b3b0c03e" class="">Matrices are generally stored in a a row-major order, which means that consecutive elements of a row reside in contiguous memory locations.</p><p id="7851f7b3-0c46-4ce0-a6ad-5de32a11ad52" class="">If a matrix multiplication is implemented using a column-major order, each statement evicts the previous elements from the cache.</p><pre id="d2522ffd-b420-4259-9055-7fb8f0521489" class="code"><code>for (int i = 0; i &lt; n; ++i)
    for (int j = 0; j &lt; m; ++j)
        for (int k = 0; k &lt; p; ++k)
            C[i][j] = C[i][j] + A[i][k] * B[k][j];</code></pre><p id="58663a11-3661-472e-bc21-657311037b2c" class="">If a matrix multiplication is implemented using a row-major order, the locality of references cause the algorithm to perform more efficiently.</p><pre id="59c305a7-2817-470a-ad10-7ef3e60f94d3" class="code"><code>for (int i = 0; i &lt; n; ++i)
    for (int k = 0; k &lt; p; ++k)
        for (int j = 0; j &lt; m; ++j)
            C[i][j] = C[i][j] + A[i][k] * B[k][j];</code></pre><h2 id="62209a5a-1dab-426c-b80f-a38246fbddd0" class="">Member variable</h2><p id="8e20df35-b2c0-4543-9322-6fd278e6805a" class="">In this example, we compute a sum from the values in an array and store the result in a member variable.</p><pre id="70df380c-c47b-4871-a489-aa582e4e592f" class="code"><code>struct MyType
{
    size_t _total = 0;

    void Update(int* values, size_t count);
};</code></pre><p id="31391ede-3df9-4f64-ad79-e23eb6b0976f" class="">When a member variable is accessed in a loop, the performance can be affected.</p><p id="dbe3bab4-3b51-46ab-aa09-2d9f2b634428" class="">Many load-store occurs, which slow down the execution of the loop.</p><pre id="68c59542-465d-44ef-9132-11a5ade8f3e2" class="code"><code>for (size_t i = 0; i &lt; count; ++i)
{
    _total += values[i];
}</code></pre><p id="f850c100-9a03-4f27-870c-1b8eb03e5959" class="">Defining a local variable to perform the calculation in the loop, and then store the result in the data member, can be much faster.</p><pre id="341f0872-3017-4525-beb7-5c3cd6b870ab" class="code"><code>size_t total = 0;
for (size_t i = 0; i &lt; count; ++i)
{
    total += values[i];
}
_total = total;</code></pre><p id="13cfe06d-ef89-4cb2-825e-6e9a95f5f33c" class="">Alternatively, the <code>restrict</code> keyword can be used as a hint for the compiler to indicate that the memory is not aliased.</p></div></article></body></html>